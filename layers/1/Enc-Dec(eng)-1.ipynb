{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Enc-Dec(eng)-1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gazrLOUy46zC","colab_type":"text"},"source":["<h1>ENCoder Decoder based machine translation tool</h1>\n","In this project a structure based on encoder-decoder is developed for machine tranlation. The source language will be english and the target language will be once spanish and then persian. The main source that the following structure has been inspired from is shown as bellow:\n","\n","https://towardsdatascience.com/word-level-english-to-marathi-neural-machine-translation-using-seq2seq-encoder-decoder-lstm-model-1a913f2dc4a7\n","\n","<h3> Downloading the dataset from google drive and making it ready</h3>"]},{"cell_type":"code","metadata":{"id":"VZ3Rjxf34PLk","colab_type":"code","outputId":"b172b9d9-3e57-4dcf-9055-4496ba0ea462","executionInfo":{"status":"ok","timestamp":1563798400809,"user_tz":-270,"elapsed":37925,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":145}},"source":["from google.colab import drive\n","import numpy as np\n","drive.mount(\"/content/drive/\")\n","\n","!cp -rd /content/drive/My\\ Drive/MSc_Projects/ANN-HW7/Dataset /content\n","!unzip /content/Dataset/SpEn.zip -d /content/dataset\n","\n","file = open(\"/content/dataset/spa.txt\", 'r+')\n","\n","total_text = file.read()\n","texts_list = total_text.split(\"\\n\")[:-1]\n","\n","print(\"This is just to check if the dataset has been downloaded properly:\\n%s\"%texts_list[np.random.randint(0, len(texts_list))])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","Archive:  /content/Dataset/SpEn.zip\n","replace /content/dataset/_about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace /content/dataset/spa.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","This is just to check if the dataset has been downloaded properly:\n","We should read one book a month at least.\tDebemos leer al menos un libro al mes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2qJrOYRlppkt","colab_type":"text"},"source":["<h1>Model implementation</h1>\n","The following cell contains the definition of the model. In this model two main steps has been implemented:\n","<ol>\n","  <li>training phase: regarding that the targets are available. Teacher forcing is used for training, thus the model is simple.</li>\n","  <li>Inference phase: in this phase the only available data is the test data. in this phase the current outputs of the decoder(LSTM) including cell, hidden state and output are used as the next inuts of the decoder. This process is done inside a while loop, untill the generated sequence reaches a maximum limit or the \"\\n\", interpreted as the end of sentence, is generated.\n"]},{"cell_type":"code","metadata":{"id":"_HCJjYV59hVz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"22e76f5c-bb53-422a-e500-73fb078d7b3e","executionInfo":{"status":"ok","timestamp":1563802380838,"user_tz":-270,"elapsed":2656,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}}},"source":["from __future__ import print_function\n","from keras.callbacks import TensorBoard\n","from keras.models import Model, load_model\n","from keras.layers import Input, LSTM, Dense\n","from keras.optimizers import RMSprop\n","import numpy as np\n","import random\n","\n","batch_size = 64\n","epochs = 40\n","latent_dim = 256\n","num_samples = 30000\n","data_path = '/content/dataset/spa.txt'\n","learning_rate = 0.01\n","LOAD = False"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"SrwHgaDryDFA","colab_type":"code","outputId":"f93dea57-56e5-45b9-892e-3a460349e1da","executionInfo":{"status":"ok","timestamp":1563802383335,"user_tz":-270,"elapsed":1818,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["from sklearn.model_selection import train_test_split\n","\n","# Vectorize the data.\n","input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    lines = f.read().split('\\n')\n","for line in lines[: min(num_samples, len(lines) - 1)]:\n","    input_text, target_text = line.split('\\t')\n","    target_text = '\\t' + target_text + '\\n'\n","    input_texts.append(input_text)\n","    target_texts.append(target_text)\n","    for char in input_text:\n","        if char not in input_characters:\n","            input_characters.add(char)\n","    for char in target_text:\n","        if char not in target_characters:\n","            target_characters.add(char)\n","\n","input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","print('Number of samples:', len(input_texts))\n","print('Number of unique input tokens:', num_encoder_tokens)\n","print('Number of unique output tokens:', num_decoder_tokens)\n","print('Max sequence length for inputs:', max_encoder_seq_length)\n","print('Max sequence length for outputs:', max_decoder_seq_length)\n","\n","input_token_index = dict(\n","    [(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict(\n","    [(char, i) for i, char in enumerate(target_characters)])\n","\n","\n","labels = {}\n","for i in range(len(input_texts)):\n","  result = []\n","  for j in range(-10, 10):\n","    if i + j >= 0 and i + j < len(input_texts) and input_texts[i] == input_texts[i + j]:\n","      result.append(target_texts[i + j])\n","  labels[input_texts[i][1:-1]] = result\n","  \n","train_x, test_x, train_y, test_y = train_test_split(input_texts, target_texts, shuffle=False, random_state=12, train_size=0.8)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Number of samples: 30000\n","Number of unique input tokens: 76\n","Number of unique output tokens: 93\n","Max sequence length for inputs: 22\n","Max sequence length for outputs: 70\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tc3IquGCxIz2","colab_type":"code","colab":{}},"source":["def embed_data(input_texts, target_texts):\n","  \n","  encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","  decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","  decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","\n","  for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","      for t, char in enumerate(input_text):\n","          encoder_input_data[i, t, input_token_index[char]] = 1.\n","      for t, char in enumerate(target_text):\n","          decoder_input_data[i, t, target_token_index[char]] = 1.\n","          if t > 0:\n","              decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n","              \n","  return encoder_input_data, decoder_input_data, decoder_target_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kaotM74uyHrA","colab_type":"code","outputId":"cbd02bce-da4e-46be-a44b-093bb8eacc51","executionInfo":{"status":"error","timestamp":1563804252906,"user_tz":-270,"elapsed":1866389,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["tbc = TensorBoard(log_dir='/content/logs/layer-1', histogram_freq=0, \n","                                  write_graph=True, write_images=True)\n","\n","\n","encoder_input_data, decoder_input_data, decoder_target_data = embed_data(train_x, train_y)\n","                            \n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","encoder_states = [state_h, state_c]\n","\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n","                                     initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","if not LOAD:\n","\n","  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","  opt = RMSprop(lr = learning_rate)\n","  \n","  print(model.summary())\n","  # Run training\n","  model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","  model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","            batch_size=batch_size,\n","            epochs=epochs,\n","            validation_split=0.2,\n","            callbacks = [tbc])\n","  # Save model\n","  model.save('layer-1.h5')\n","  \n","if LOAD:\n","  !cp /content/drive/My\\ Drive/MSc_Projects/ANN-HW7/layers/1/layer-1.h5 /content/\n","  model = load_model(\"layer-1.h5\")\n","  print(model.summary())\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0722 13:33:09.061563 139659302008704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0722 13:33:09.064498 139659302008704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0722 13:33:09.070994 139659302008704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0722 13:33:10.321313 139659302008704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0722 13:33:10.353256 139659302008704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0722 13:33:10.495195 139659302008704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, 76)     0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, None, 93)     0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, 256), (None, 340992      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   [(None, None, 256),  358400      input_2[0][0]                    \n","                                                                 lstm_1[0][1]                     \n","                                                                 lstm_1[0][2]                     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, None, 93)     23901       lstm_2[0][0]                     \n","==================================================================================================\n","Total params: 723,293\n","Trainable params: 723,293\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"},{"output_type":"stream","text":["W0722 13:33:12.243598 139659302008704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 19200 samples, validate on 4800 samples\n"],"name":"stdout"},{"output_type":"stream","text":["W0722 13:33:13.660959 139659302008704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","W0722 13:33:13.662300 139659302008704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/40\n","19200/19200 [==============================] - 61s 3ms/step - loss: 0.6910 - val_loss: 0.7058\n","Epoch 2/40\n","19200/19200 [==============================] - 60s 3ms/step - loss: 0.5302 - val_loss: 0.6185\n","Epoch 3/40\n","19200/19200 [==============================] - 60s 3ms/step - loss: 0.4729 - val_loss: 0.5688\n","Epoch 4/40\n","19200/19200 [==============================] - 63s 3ms/step - loss: 0.4331 - val_loss: 0.5357\n","Epoch 5/40\n","19200/19200 [==============================] - 61s 3ms/step - loss: 0.4023 - val_loss: 0.5127\n","Epoch 6/40\n","19200/19200 [==============================] - 61s 3ms/step - loss: 0.3786 - val_loss: 0.4869\n","Epoch 7/40\n","19200/19200 [==============================] - 71s 4ms/step - loss: 0.3588 - val_loss: 0.4722\n","Epoch 8/40\n","19200/19200 [==============================] - 78s 4ms/step - loss: 0.3409 - val_loss: 0.4541\n","Epoch 9/40\n","19200/19200 [==============================] - 78s 4ms/step - loss: 0.3260 - val_loss: 0.4467\n","Epoch 10/40\n","19200/19200 [==============================] - 77s 4ms/step - loss: 0.3130 - val_loss: 0.4315\n","Epoch 11/40\n","19200/19200 [==============================] - 76s 4ms/step - loss: 0.3012 - val_loss: 0.4247\n","Epoch 12/40\n","19200/19200 [==============================] - 78s 4ms/step - loss: 0.2905 - val_loss: 0.4170\n","Epoch 13/40\n","19200/19200 [==============================] - 80s 4ms/step - loss: 0.2809 - val_loss: 0.4117\n","Epoch 14/40\n","19200/19200 [==============================] - 82s 4ms/step - loss: 0.2720 - val_loss: 0.4070\n","Epoch 15/40\n","19200/19200 [==============================] - 79s 4ms/step - loss: 0.2638 - val_loss: 0.4046\n","Epoch 16/40\n","19200/19200 [==============================] - 68s 4ms/step - loss: 0.2560 - val_loss: 0.4019\n","Epoch 17/40\n","19200/19200 [==============================] - 64s 3ms/step - loss: 0.2490 - val_loss: 0.4001\n","Epoch 18/40\n","19200/19200 [==============================] - 75s 4ms/step - loss: 0.2422 - val_loss: 0.3972\n","Epoch 19/40\n","19200/19200 [==============================] - 75s 4ms/step - loss: 0.2358 - val_loss: 0.3962\n","Epoch 20/40\n","19200/19200 [==============================] - 76s 4ms/step - loss: 0.2299 - val_loss: 0.3978\n","Epoch 21/40\n","19200/19200 [==============================] - 58s 3ms/step - loss: 0.2244 - val_loss: 0.3969\n","Epoch 22/40\n","19200/19200 [==============================] - 58s 3ms/step - loss: 0.2189 - val_loss: 0.3985\n","Epoch 23/40\n","19200/19200 [==============================] - 58s 3ms/step - loss: 0.2136 - val_loss: 0.3990\n","Epoch 24/40\n","19200/19200 [==============================] - 57s 3ms/step - loss: 0.2086 - val_loss: 0.4012\n","Epoch 25/40\n","19200/19200 [==============================] - 57s 3ms/step - loss: 0.2039 - val_loss: 0.4015\n","Epoch 26/40\n","19200/19200 [==============================] - 57s 3ms/step - loss: 0.1993 - val_loss: 0.4041\n","Epoch 27/40\n","19200/19200 [==============================] - 57s 3ms/step - loss: 0.1949 - val_loss: 0.4050\n","Epoch 28/40\n","11072/19200 [================>.............] - ETA: 22s - loss: 0.1874"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-20661d400a00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             callbacks = [tbc])\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layer-1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"5K0-fhIu_ZF4","colab_type":"code","outputId":"314acac7-20e5-4395-e4fb-6147f6eb19ff","executionInfo":{"status":"ok","timestamp":1563804326690,"user_tz":-270,"elapsed":2023,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if not LOAD:\n","    model.save('layer-1.h5')\n","    \n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)\n","\n","reverse_input_char_index = dict(\n","    (i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict(\n","    (i, char) for char, i in target_token_index.items())\n","\n","\n","def decode_sequence(input_seq):\n","    states_value = encoder_model.predict(input_seq)\n","\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        states_value = [h, c]\n","\n","    return decoded_sentence\n","\n","for i in range(20):\n","    seq_index = random.randint(1, 100)  \n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)[:-1]\n","    reference_sent = train_y[seq_index][1:-1]\n","    print('-')\n","    print('Input sentence:', train_x[seq_index])\n","    print('Decoded sentence:', decoded_sentence)\n","    print('reference sentence: ', reference_sent)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  '. They will not be included '\n"],"name":"stderr"},{"output_type":"stream","text":["-\n","Input sentence: I lied.\n","Decoded sentence: Yo los dejé.\n","reference sentence:  Mentí.\n","-\n","Input sentence: We try.\n","Decoded sentence: Nos vamos.\n","reference sentence:  Lo procuramos.\n","-\n","Input sentence: Fire!\n","Decoded sentence: ¡La de paciente!\n","reference sentence:  ¡Incendio!\n","-\n","Input sentence: Ask Tom.\n","Decoded sentence: Pregúntale a Tom.\n","reference sentence:  Pregúntale a Tom.\n","-\n","Input sentence: I sang.\n","Decoded sentence: Yo conozco.\n","reference sentence:  Canté.\n","-\n","Input sentence: Come on.\n","Decoded sentence: ¡Vente aquí!\n","reference sentence:  Ándale.\n","-\n","Input sentence: Go.\n","Decoded sentence: Vete.\n","reference sentence:  Vaya.\n","-\n","Input sentence: Fire!\n","Decoded sentence: ¡La de paciente!\n","reference sentence:  ¡Fuego!\n","-\n","Input sentence: Fire!\n","Decoded sentence: ¡La de paciente!\n","reference sentence:  ¡Disparad!\n","-\n","Input sentence: Attack!\n","Decoded sentence: ¡Acas! de paga!\n","reference sentence:  ¡Al ataque!\n","-\n","Input sentence: Stop!\n","Decoded sentence: ¡Para!\n","reference sentence:  ¡Parad!\n","-\n","Input sentence: Be kind.\n","Decoded sentence: Sé espeta.\n","reference sentence:  Sean gentiles.\n","-\n","Input sentence: Call me.\n","Decoded sentence: ¡Llama a mi mamá!\n","reference sentence:  Llamadme.\n","-\n","Input sentence: Thanks.\n","Decoded sentence: Gracias.\n","reference sentence:  Gracias.\n","-\n","Input sentence: No way!\n","Decoded sentence: ¡No salivinndo!\n","reference sentence:  ¡De ningún modo!\n","-\n","Input sentence: We try.\n","Decoded sentence: Nos vamos.\n","reference sentence:  Lo procuramos.\n","-\n","Input sentence: Call me.\n","Decoded sentence: ¡Llama a mi mamá!\n","reference sentence:  Llamadme.\n","-\n","Input sentence: Get out.\n","Decoded sentence: Salga esto.\n","reference sentence:  Sal.\n","-\n","Input sentence: Go on.\n","Decoded sentence: ¡Vete a de mirdo!\n","reference sentence:  Continúa.\n","-\n","Input sentence: I try.\n","Decoded sentence: Yo casilé.\n","reference sentence:  Lo intento.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-wE5sQ69y3-F","colab_type":"code","outputId":"850ee7b3-44d3-4bc7-8987-1ac6a2384731","executionInfo":{"status":"ok","timestamp":1563804334691,"user_tz":-270,"elapsed":4578,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","!cp /content/layer-1.h5  /content/drive/My\\ Drive/MSc_Projects/ANN-HW7/layers/1/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"teUhDjkkSri5","colab_type":"text"},"source":["<h1> Calculating the BLEU metric</h1>\n"]},{"cell_type":"code","metadata":{"id":"ebsikjsk5BF3","colab_type":"code","colab":{}},"source":["from nltk.tokenize import word_tokenize\n","\n","def tokenize(sentences):\n","  temp = []\n","  for sent in sentences:\n","    temp.append(word_tokenize(sentence))\n","  return temp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArIbp0I5zC22","colab_type":"code","outputId":"f525c5d9-9cb6-42c7-d50b-0e655f5392a4","executionInfo":{"status":"ok","timestamp":1563805227314,"user_tz":-270,"elapsed":45246,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":305}},"source":["from nltk.translate.bleu_score import sentence_bleu\n","import nltk\n","nltk.download(\"punkt\")\n","\n","encoder_input_data, _, _ = embed_data(test_x, test_y)\n","sentences_bleu = []\n","\n","for i, sentence in enumerate(test_x[:1000]):\n","  if int(i % 200) == 0:\n","    print(\"%d%%\"%(i *100 / len(test_x[:1000])))\n","  input_seq = encoder_input_data[i: i + 1]\n","  decoded_sentence = decode_sequence(input_seq)[:-1]\n","  temp = tokenize(labels[sentence[1:-1]])\n","  sentences_bleu.append(sentence_bleu(temp, word_tokenize(decoded_sentence)))\n","\n","print(\"The BLEU value calculated: %.2f\" % np.average(sentences_bleu))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","0%\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["20%\n","40%\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["60%\n","80%\n","The BLEU value calculated: 0.54\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xrsUaKomLHfS","colab_type":"text"},"source":["<h1>Ploting the losses using Tensorboard</h1>"]},{"cell_type":"code","metadata":{"id":"wONlg_6LMsRm","colab_type":"code","outputId":"706864c5-6859-4c84-e729-9ec47d549f8e","executionInfo":{"status":"error","timestamp":1563798670024,"user_tz":-270,"elapsed":306880,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# %load_ext tensorboard\n","!kill 2525\n","%tensorboard --logdir /content/logs"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/bin/bash: line 0: kill: (2525) - No such process\n"],"name":"stdout"},{"output_type":"stream","text":["UsageError: Line magic function `%tensorboard` not found.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"1uzjd8VSOg0C","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}