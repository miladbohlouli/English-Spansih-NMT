{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Enc-Dec(eng)-2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gazrLOUy46zC","colab_type":"text"},"source":["<h1>ENCoder Decoder based machine translation tool</h1>\n","In this project a structure based on encoder-decoder is developed for machine tranlation. The source language will be english and the target language will be once spanish and then persian. The main source that the following structure has been inspired from is shown as bellow:\n","\n","https://towardsdatascience.com/word-level-english-to-marathi-neural-machine-translation-using-seq2seq-encoder-decoder-lstm-model-1a913f2dc4a7\n","\n","<h3> Downloading the dataset from google drive and making it ready</h3>"]},{"cell_type":"code","metadata":{"id":"VZ3Rjxf34PLk","colab_type":"code","outputId":"0bbc83db-bbcb-4aa4-bfe9-8324f5cd941c","executionInfo":{"status":"ok","timestamp":1563790951932,"user_tz":-270,"elapsed":81623,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["from google.colab import drive\n","import numpy as np\n","drive.mount(\"/content/drive/\")\n","\n","!cp -rd /content/drive/My\\ Drive/MSc_Projects/ANN-HW7/Dataset /content\n","!unzip /content/Dataset/SpEn.zip -d /content/dataset\n","\n","file = open(\"/content/dataset/spa.txt\", 'r+')\n","\n","total_text = file.read()\n","texts_list = total_text.split(\"\\n\")[:-1]\n","\n","print(\"This is just to check if the dataset has been downloaded properly:\\n%s\"%texts_list[np.random.randint(0, len(texts_list))])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","Archive:  /content/Dataset/SpEn.zip\n","replace /content/dataset/_about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: This is just to check if the dataset has been downloaded properly:\n","I do not play tennis as much as I used to.\tNo juego tanto al tenis como antes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2qJrOYRlppkt","colab_type":"text"},"source":["<h1>Model implementation</h1>\n","The following cell contains the definition of the model. In this model two main steps has been implemented:\n","<ol>\n","  <li>training phase: regarding that the targets are available. Teacher forcing is used for training, thus the model is simple.</li>\n","  <li>Inference phase: in this phase the only available data is the test data. in this phase the current outputs of the decoder(LSTM) including cell, hidden state and output are used as the next inuts of the decoder. This process is done inside a while loop, untill the generated sequence reaches a maximum limit or the \"\\n\", interpreted as the end of sentence, is generated.\n"]},{"cell_type":"code","metadata":{"id":"_HCJjYV59hVz","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","from keras.callbacks import TensorBoard\n","from keras.models import Model, load_model\n","from keras.layers import Input, LSTM, Dense\n","from keras.optimizers import RMSprop\n","import numpy as np\n","\n","batch_size = 64\n","epochs = 40\n","latent_dim = 256\n","num_samples = 30000\n","data_path = '/content/dataset/spa.txt'\n","learning_rate = 0.01\n","\n","LOAD = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrwHgaDryDFA","colab_type":"code","outputId":"7fb5ecc0-7af1-4ac1-ebc7-598961103af4","executionInfo":{"status":"ok","timestamp":1563805256266,"user_tz":-270,"elapsed":1091,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["from sklearn.model_selection import train_test_split\n","\n","# Vectorize the data.\n","input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    lines = f.read().split('\\n')\n","for line in lines[: min(num_samples, len(lines) - 1)]:\n","    input_text, target_text = line.split('\\t')\n","    target_text = '\\t' + target_text + '\\n'\n","    input_texts.append(input_text)\n","    target_texts.append(target_text)\n","    for char in input_text:\n","        if char not in input_characters:\n","            input_characters.add(char)\n","    for char in target_text:\n","        if char not in target_characters:\n","            target_characters.add(char)\n","\n","input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","print('Number of samples:', len(input_texts))\n","print('Number of unique input tokens:', num_encoder_tokens)\n","print('Number of unique output tokens:', num_decoder_tokens)\n","print('Max sequence length for inputs:', max_encoder_seq_length)\n","print('Max sequence length for outputs:', max_decoder_seq_length)\n","\n","input_token_index = dict(\n","    [(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict(\n","    [(char, i) for i, char in enumerate(target_characters)])\n","\n","\n","labels = {}\n","for i in range(len(input_texts)):\n","  result = []\n","  for j in range(-10, 10):\n","    if i + j >= 0 and i + j < len(input_texts) and input_texts[i] == input_texts[i + j]:\n","      result.append(target_texts[i + j])\n","  labels[input_texts[i][1:-1]] = result\n","  \n","train_x, test_x, train_y, test_y = train_test_split(input_texts, target_texts, shuffle=False, random_state=12, train_size=0.8)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Number of samples: 30000\n","Number of unique input tokens: 76\n","Number of unique output tokens: 93\n","Max sequence length for inputs: 22\n","Max sequence length for outputs: 70\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tc3IquGCxIz2","colab_type":"code","colab":{}},"source":["def embed_data(input_texts, target_texts):\n","  \n","  encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","  decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","  decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","\n","  for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","      for t, char in enumerate(input_text):\n","          encoder_input_data[i, t, input_token_index[char]] = 1.\n","      for t, char in enumerate(target_text):\n","          decoder_input_data[i, t, target_token_index[char]] = 1.\n","          if t > 0:\n","              decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n","              \n","  return encoder_input_data, decoder_input_data, decoder_target_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kaotM74uyHrA","colab_type":"code","outputId":"8ad22978-5b95-41da-a498-0e562e51077b","executionInfo":{"status":"error","timestamp":1563806297661,"user_tz":-270,"elapsed":1027169,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["tbc = TensorBoard(log_dir='/content/logs/layer-2/', histogram_freq=0, \n","                                  write_graph=True, write_images=True)\n","\n","\n","encoder_input_data, decoder_input_data, decoder_target_data = embed_data(train_x, train_y)\n","                            \n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","\n","#layer 1\n","encoder = LSTM(latent_dim, return_state=True, return_sequences=True)\n","encoder_outputs, state_h1, state_c1 = encoder(encoder_inputs)\n","\n","#layer 2\n","encoder1 = LSTM(latent_dim, return_state=True)\n","_, state_h, state_c = encoder1(encoder_outputs)\n","\n","encoder_states = [state_h, state_c]\n","\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n","                                     initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","if not LOAD:\n","\n","  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","  print(model.summary())\n","  \n","  opt = RMSprop(lr=learning_rate)\n","  # Run training\n","  model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","  model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","            batch_size=batch_size,\n","            epochs=epochs,\n","            validation_split=0.2,\n","            callbacks = [tbc])\n","  # Save model\n","  \n","  \n","if LOAD:\n","  !cp /content/drive/My\\ Drive/MSc_Projects/ANN-HW7/layers/2/layer-2.h5 /content/\n","  model = load_model(\"layer-2.h5\")\n","  print(model.summary())\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_8 (InputLayer)            (None, None, 76)     0                                            \n","__________________________________________________________________________________________________\n","lstm_8 (LSTM)                   [(None, None, 256),  340992      input_8[0][0]                    \n","__________________________________________________________________________________________________\n","input_9 (InputLayer)            (None, None, 93)     0                                            \n","__________________________________________________________________________________________________\n","lstm_9 (LSTM)                   [(None, 256), (None, 525312      lstm_8[0][0]                     \n","__________________________________________________________________________________________________\n","lstm_10 (LSTM)                  [(None, None, 256),  358400      input_9[0][0]                    \n","                                                                 lstm_9[0][1]                     \n","                                                                 lstm_9[0][2]                     \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, None, 93)     23901       lstm_10[0][0]                    \n","==================================================================================================\n","Total params: 1,248,605\n","Trainable params: 1,248,605\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Train on 19200 samples, validate on 4800 samples\n","Epoch 1/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.6872 - val_loss: 0.6854\n","Epoch 2/40\n","19200/19200 [==============================] - 52s 3ms/step - loss: 0.5119 - val_loss: 0.6110\n","Epoch 3/40\n","19200/19200 [==============================] - 45s 2ms/step - loss: 0.4552 - val_loss: 0.5538\n","Epoch 4/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.4154 - val_loss: 0.5211\n","Epoch 5/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.3841 - val_loss: 0.4928\n","Epoch 6/40\n","19200/19200 [==============================] - 44s 2ms/step - loss: 0.3589 - val_loss: 0.4739\n","Epoch 7/40\n","19200/19200 [==============================] - 44s 2ms/step - loss: 0.3381 - val_loss: 0.4553\n","Epoch 8/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.3200 - val_loss: 0.4444\n","Epoch 9/40\n","19200/19200 [==============================] - 45s 2ms/step - loss: 0.3044 - val_loss: 0.4305\n","Epoch 10/40\n","19200/19200 [==============================] - 45s 2ms/step - loss: 0.2903 - val_loss: 0.4247\n","Epoch 11/40\n","19200/19200 [==============================] - 44s 2ms/step - loss: 0.2777 - val_loss: 0.4172\n","Epoch 12/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.2662 - val_loss: 0.4128\n","Epoch 13/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.2553 - val_loss: 0.4080\n","Epoch 14/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.2452 - val_loss: 0.4065\n","Epoch 15/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.2358 - val_loss: 0.4022\n","Epoch 16/40\n","19200/19200 [==============================] - 45s 2ms/step - loss: 0.2267 - val_loss: 0.4049\n","Epoch 17/40\n","19200/19200 [==============================] - 47s 2ms/step - loss: 0.2184 - val_loss: 0.4048\n","Epoch 18/40\n","19200/19200 [==============================] - 45s 2ms/step - loss: 0.2102 - val_loss: 0.4031\n","Epoch 19/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.2024 - val_loss: 0.4074\n","Epoch 20/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.1950 - val_loss: 0.4091\n","Epoch 21/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.1880 - val_loss: 0.4117\n","Epoch 22/40\n","19200/19200 [==============================] - 46s 2ms/step - loss: 0.1811 - val_loss: 0.4145\n","Epoch 23/40\n"," 5248/19200 [=======>......................] - ETA: 29s - loss: 0.1700"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-28d03144b815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             callbacks = [tbc])\n\u001b[0m\u001b[1;32m     40\u001b[0m   \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layer-2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"5K0-fhIu_ZF4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":433},"outputId":"423b0e0e-fe73-4c36-8910-a080dd675906","executionInfo":{"status":"ok","timestamp":1563806369924,"user_tz":-270,"elapsed":2262,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}}},"source":["if not LOAD:\n","  model.save('layer-2.h5')\n","\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)\n","\n","reverse_input_char_index = dict(\n","    (i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict(\n","    (i, char) for char, i in target_token_index.items())\n","\n","\n","def decode_sequence(input_seq):\n","    states_value = encoder_model.predict(input_seq)\n","\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        states_value = [h, c]\n","\n","    return decoded_sentence\n","\n","decoded_sentences = []\n","reference_sents = []\n","\n","for seq_index in range(5):\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    decoded_sentences.append(decode_sequence(input_seq)[:-1])\n","    reference_sents.append(target_texts[seq_index][1:-1])\n","    print('-')\n","    print('Input sentence:', test_x[seq_index])\n","    print('Decoded sentence:', decoded_sentences[seq_index])\n","    print('reference sentence: ', reference_sents[seq_index])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_10 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_9/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_9/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  '. They will not be included '\n"],"name":"stderr"},{"output_type":"stream","text":["-\n","Input sentence: I didn't ask for you.\n","Decoded sentence: Vaya.\n","reference sentence:  Ve.\n","-\n","Input sentence: I didn't believe you.\n","Decoded sentence: Vaya.\n","reference sentence:  Vete.\n","-\n","Input sentence: I didn't do anything.\n","Decoded sentence: Vaya.\n","reference sentence:  Vaya.\n","-\n","Input sentence: I didn't do anything.\n","Decoded sentence: Vaya.\n","reference sentence:  Váyase.\n","-\n","Input sentence: I didn't do it alone.\n","Decoded sentence: Hola.\n","reference sentence:  Hola.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-wE5sQ69y3-F","colab_type":"code","outputId":"3651045b-e219-44ec-fd34-f634b16c19dc","executionInfo":{"status":"ok","timestamp":1563806382272,"user_tz":-270,"elapsed":4077,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","!cp /content/layer-2.h5  /content/drive/My\\ Drive/MSc_Projects/ANN-HW7/layers/2/"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"teUhDjkkSri5","colab_type":"text"},"source":["<h1> Calculating the BLEU metric</h1>\n"]},{"cell_type":"code","metadata":{"id":"ebsikjsk5BF3","colab_type":"code","colab":{}},"source":["from nltk.tokenize import word_tokenize\n","\n","def tokenize(sentences):\n","  temp = []\n","  for sent in sentences:\n","    temp.append(word_tokenize(sentence))\n","  return temp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArIbp0I5zC22","colab_type":"code","outputId":"6071f6a4-63cf-4a3a-be03-fb7207d9593c","executionInfo":{"status":"ok","timestamp":1563806446677,"user_tz":-270,"elapsed":42396,"user":{"displayName":"milad bohlouli","photoUrl":"","userId":"17742718220684002192"}},"colab":{"base_uri":"https://localhost:8080/","height":305}},"source":["from nltk.translate.bleu_score import sentence_bleu\n","import nltk\n","nltk.download(\"punkt\")\n","\n","encoder_input_data, _, _ = embed_data(test_x, test_y)\n","sentences_bleu = []\n","\n","for i, sentence in enumerate(test_x[:1000]):\n","  if int(i % 200) == 0:\n","    print(\"%d%%\"%(i *100 / len(test_x[:1000])))\n","  input_seq = encoder_input_data[i: i + 1]\n","  decoded_sentence = decode_sequence(input_seq)[:-1]\n","  temp = tokenize(labels[sentence[1:-1]])\n","  sentences_bleu.append(sentence_bleu(temp, word_tokenize(decoded_sentence)))\n","\n","print(\"The BLEU value calculated: %.2f\" % np.average(sentences_bleu))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","0%\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["20%\n","40%\n","60%\n","80%\n","The BLEU value calculated: 0.52\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xrsUaKomLHfS","colab_type":"text"},"source":["<h1>Ploting the losses using Tensorboard</h1>"]},{"cell_type":"code","metadata":{"id":"wONlg_6LMsRm","colab_type":"code","colab":{}},"source":["# %load_ext tensorboard\n","!kill 2525\n","%tensorboard --logdir /content/logs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1uzjd8VSOg0C","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}