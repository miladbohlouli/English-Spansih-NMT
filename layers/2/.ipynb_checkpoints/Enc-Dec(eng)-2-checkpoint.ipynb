{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gazrLOUy46zC"
   },
   "source": [
    "<h1>ENCoder Decoder based machine translation tool</h1>\n",
    "In this project a structure based on encoder-decoder is developed for machine tranlation. The source language will be english and the target language will be once spanish and then persian. The main source that the following structure has been inspired from is shown as bellow:\n",
    "\n",
    "https://towardsdatascience.com/word-level-english-to-marathi-neural-machine-translation-using-seq2seq-encoder-decoder-lstm-model-1a913f2dc4a7\n",
    "\n",
    "<h3> Downloading the dataset from google drive and making it ready</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 81623,
     "status": "ok",
     "timestamp": 1563790951932,
     "user": {
      "displayName": "milad bohlouli",
      "photoUrl": "",
      "userId": "17742718220684002192"
     },
     "user_tz": -270
    },
    "id": "VZ3Rjxf34PLk",
    "outputId": "0bbc83db-bbcb-4aa4-bfe9-8324f5cd941c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import numpy as np\n",
    "drive.mount(\"/content/drive/\")\n",
    "\n",
    "!cp -rd /content/drive/My\\ Drive/MSc_Projects/ANN-HW7/Dataset /content\n",
    "!unzip /content/Dataset/SpEn.zip -d /content/dataset\n",
    "\n",
    "file = open(\"/content/dataset/spa.txt\", 'r+')\n",
    "\n",
    "total_text = file.read()\n",
    "texts_list = total_text.split(\"\\n\")[:-1]\n",
    "\n",
    "print(\"This is just to check if the dataset has been downloaded properly:\\n%s\"%texts_list[np.random.randint(0, len(texts_list))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2qJrOYRlppkt"
   },
   "source": [
    "<h1>Model implementation</h1>\n",
    "The following cell contains the definition of the model. In this model two main steps has been implemented:\n",
    "<ol>\n",
    "  <li>training phase: regarding that the targets are available. Teacher forcing is used for training, thus the model is simple.</li>\n",
    "  <li>Inference phase: in this phase the only available data is the test data. in this phase the current outputs of the decoder(LSTM) including cell, hidden state and output are used as the next inuts of the decoder. This process is done inside a while loop, untill the generated sequence reaches a maximum limit or the \"\\n\", interpreted as the end of sentence, is generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HCJjYV59hVz"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "latent_dim = 256\n",
    "num_samples = 30000\n",
    "data_path = '/content/dataset/spa.txt'\n",
    "learning_rate = 0.01\n",
    "\n",
    "LOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1563805256266,
     "user": {
      "displayName": "milad bohlouli",
      "photoUrl": "",
      "userId": "17742718220684002192"
     },
     "user_tz": -270
    },
    "id": "SrwHgaDryDFA",
    "outputId": "7fb5ecc0-7af1-4ac1-ebc7-598961103af4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "\n",
    "labels = {}\n",
    "for i in range(len(input_texts)):\n",
    "  result = []\n",
    "  for j in range(-10, 10):\n",
    "    if i + j >= 0 and i + j < len(input_texts) and input_texts[i] == input_texts[i + j]:\n",
    "      result.append(target_texts[i + j])\n",
    "  labels[input_texts[i][1:-1]] = result\n",
    "  \n",
    "train_x, test_x, train_y, test_y = train_test_split(input_texts, target_texts, shuffle=False, random_state=12, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tc3IquGCxIz2"
   },
   "outputs": [],
   "source": [
    "def embed_data(input_texts, target_texts):\n",
    "  \n",
    "  encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "  decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "  decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "  for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "      for t, char in enumerate(input_text):\n",
    "          encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "      for t, char in enumerate(target_text):\n",
    "          decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "          if t > 0:\n",
    "              decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "              \n",
    "  return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1027169,
     "status": "error",
     "timestamp": 1563806297661,
     "user": {
      "displayName": "milad bohlouli",
      "photoUrl": "",
      "userId": "17742718220684002192"
     },
     "user_tz": -270
    },
    "id": "kaotM74uyHrA",
    "outputId": "8ad22978-5b95-41da-a498-0e562e51077b"
   },
   "outputs": [],
   "source": [
    "tbc = TensorBoard(log_dir='/content/logs/layer-2/', histogram_freq=0, \n",
    "                                  write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "encoder_input_data, decoder_input_data, decoder_target_data = embed_data(train_x, train_y)\n",
    "                            \n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "\n",
    "#layer 1\n",
    "encoder = LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "encoder_outputs, state_h1, state_c1 = encoder(encoder_inputs)\n",
    "\n",
    "#layer 2\n",
    "encoder1 = LSTM(latent_dim, return_state=True)\n",
    "_, state_h, state_c = encoder1(encoder_outputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "if not LOAD:\n",
    "\n",
    "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "  print(model.summary())\n",
    "  \n",
    "  opt = RMSprop(lr=learning_rate)\n",
    "  # Run training\n",
    "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "  model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.2,\n",
    "            callbacks = [tbc])\n",
    "  # Save model\n",
    "  \n",
    "  \n",
    "if LOAD:\n",
    "  !cp /content/drive/My\\ Drive/MSc_Projects/ANN-HW7/layers/2/layer-2.h5 /content/\n",
    "  model = load_model(\"layer-2.h5\")\n",
    "  print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2262,
     "status": "ok",
     "timestamp": 1563806369924,
     "user": {
      "displayName": "milad bohlouli",
      "photoUrl": "",
      "userId": "17742718220684002192"
     },
     "user_tz": -270
    },
    "id": "5K0-fhIu_ZF4",
    "outputId": "423b0e0e-fe73-4c36-8910-a080dd675906"
   },
   "outputs": [],
   "source": [
    "if not LOAD:\n",
    "  model.save('layer-2.h5')\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "decoded_sentences = []\n",
    "reference_sents = []\n",
    "\n",
    "for seq_index in range(5):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentences.append(decode_sequence(input_seq)[:-1])\n",
    "    reference_sents.append(target_texts[seq_index][1:-1])\n",
    "    print('-')\n",
    "    print('Input sentence:', test_x[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentences[seq_index])\n",
    "    print('reference sentence: ', reference_sents[seq_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4077,
     "status": "ok",
     "timestamp": 1563806382272,
     "user": {
      "displayName": "milad bohlouli",
      "photoUrl": "",
      "userId": "17742718220684002192"
     },
     "user_tz": -270
    },
    "id": "-wE5sQ69y3-F",
    "outputId": "3651045b-e219-44ec-fd34-f634b16c19dc"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "!cp /content/layer-2.h5  /content/drive/My\\ Drive/MSc_Projects/ANN-HW7/layers/2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teUhDjkkSri5"
   },
   "source": [
    "<h1> Calculating the BLEU metric</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebsikjsk5BF3"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(sentences):\n",
    "  temp = []\n",
    "  for sent in sentences:\n",
    "    temp.append(word_tokenize(sentence))\n",
    "  return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42396,
     "status": "ok",
     "timestamp": 1563806446677,
     "user": {
      "displayName": "milad bohlouli",
      "photoUrl": "",
      "userId": "17742718220684002192"
     },
     "user_tz": -270
    },
    "id": "ArIbp0I5zC22",
    "outputId": "6071f6a4-63cf-4a3a-be03-fb7207d9593c"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "encoder_input_data, _, _ = embed_data(test_x, test_y)\n",
    "sentences_bleu = []\n",
    "\n",
    "for i, sentence in enumerate(test_x[:1000]):\n",
    "  if int(i % 200) == 0:\n",
    "    print(\"%d%%\"%(i *100 / len(test_x[:1000])))\n",
    "  input_seq = encoder_input_data[i: i + 1]\n",
    "  decoded_sentence = decode_sequence(input_seq)[:-1]\n",
    "  temp = tokenize(labels[sentence[1:-1]])\n",
    "  sentences_bleu.append(sentence_bleu(temp, word_tokenize(decoded_sentence)))\n",
    "\n",
    "print(\"The BLEU value calculated: %.2f\" % np.average(sentences_bleu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrsUaKomLHfS"
   },
   "source": [
    "<h1>Ploting the losses using Tensorboard</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wONlg_6LMsRm"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "!kill 2525\n",
    "%tensorboard --logdir /content/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1uzjd8VSOg0C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Enc-Dec(eng)-2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
